import os
from langchain_community.document_loaders import TextLoader
from langchain_core.documents import Document

def load_and_process_documents(data_folder="./data"):
    """
    Basit text dosyasÄ± yÃ¼kleyici
    """
    documents = []
    
    print("ğŸ“ Veri dosyalarÄ± taranÄ±yor...")
    
    # data klasÃ¶rÃ¼ yoksa oluÅŸtur
    os.makedirs(data_folder, exist_ok=True)
    
    # data klasÃ¶rÃ¼ndeki tÃ¼m dosyalarÄ± kontrol et
    for file in os.listdir(data_folder):
        file_path = os.path.join(data_folder, file)
        
        if file.endswith(".txt"):
            print(f"ğŸ“ Text dosyasÄ± yÃ¼kleniyor: {file}")
            try:
                loader = TextLoader(file_path, encoding='utf-8')
                loaded_docs = loader.load()
                documents.extend(loaded_docs)
                print(f"âœ… {file} baÅŸarÄ±yla yÃ¼klendi")
            except Exception as e:
                print(f"âŒ {file} yÃ¼klenirken hata: {e}")
    
    if not documents:
        print("âš ï¸ HiÃ§ dokÃ¼man bulunamadÄ±! LÃ¼tfen data/ klasÃ¶rÃ¼ne PDF veya txt dosyasÄ± ekleyin.")
        return []
    
    print(f"ğŸ“Š Toplam {len(documents)} dokÃ¼man yÃ¼klendi")
    
    # BASÄ°T metin bÃ¶lme
    texts = []
    for doc in documents:
        content = doc.page_content
        # 1000 karakterlik parÃ§alara bÃ¶l
        for i in range(0, len(content), 800):
            chunk = content[i:i+1000]
            if len(chunk.strip()) > 50:  # BoÅŸ parÃ§alarÄ± atla
                new_doc = Document(
                    page_content=chunk,
                    metadata=doc.metadata.copy()
                )
                texts.append(new_doc)
    
    print(f"âœ‚ï¸ {len(documents)} dokÃ¼man â†’ {len(texts)} metin parÃ§asÄ± oluÅŸturuldu")
    
    return texts

if __name__ == "__main__":
    texts = load_and_process_documents()
    if texts:
        print(f"\nğŸ§ª Ä°lk parÃ§a Ã¶nizleme:")
        print(f"Ä°Ã§erik: {texts[0].page_content[:200]}...")
        print(f"Kaynak: {texts[0].metadata.get('source', 'Bilinmiyor')}")